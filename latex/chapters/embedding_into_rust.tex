\section{Embedding into Rust}

The main challenge in implementing the scheme described above is how to evaluate $sdeval(f, \cdot)$ for some probabilistic program $f$, since it requires us to interfere with the ordinary execution of $f$ as a function.

One option would be to define a separate language for probabilistic programs and simply define evaluation for functions in it to be $sdeval$ \cite{carpenter2017stan}. However, this would mean that any features we would like to use in writing probabilistic programs, like common data structures and functions, would have to be re-implemented in, or at least manually exposed to, our new language.

Another option would be to embed our probabilistic programs in an existing programming language and build a new interpreter for the composite language that can differentiate between and handle both all ordinary preexisting features in the language and our probabilistic programs \cite{goodman2012church}.

A third option would be to take an existing programming language together with an existing interpreter or compiler for it, and just insert a step before interpretation/compilation where we translate any probabilistic program $f$ in the code into an ordinary function $f'$, where $f'(t) = sdeval(f,t)$ for a trace $t$ \cite{wingate2011lightweight} \cite{cusumano2019gen}. This way we can utilize all the existing tooling and libraries that exist for the host language, and only have to concern ourselves with the comparatively simple task of translation.

We implement here this third option for the compiled imperative programming language Rust \cite{RustProg37:online}. Thanks to Rust's integrated macro system, we can define the translation of probabilistic programs into ordinary functions without having to manually insert any additional compilation step. This way our implementation can exist as on ordinary library ("crate" in the Rust terminology), which can be imported and used like any other library \footnote{The current development version of the implementation can be found at \cite{GitHubGa46:online}}.

The part of the macro system of Rust that matters to us here are "procedural macros". A procedural macro is simply a function which takes a list of tokens (as defined by the Rust tokenizer) as input and gives a list of tokens as output \cite{Procedur10:online}. In our case, we will define three macros, one "attribute macro" and two "function-like macros". The difference between these simply being that an attribute macro is applied by annotating it to an existing syntax component in the code, in our case a function definition, while a function-like macro is applied like a regular function.

\subsection{prob}

The attribute macro we define, which we shall call \lstinline{prob}, turns a probabilistic program $f$ into a function which returns a closure, which in turn captures all arguments to the original probabilistic program. This closure is the implementation of $sdeval(f,\cdot)$. It takes a predefined trace that (possibly incompletely) determines the execution and returns a valid trace of the execution, it's associated probability\footnote{For improved stability, in the actual implementation, we work with log probabilities instead of probabilities directly.}, and the actual return value of the probabilistic program.

\begin{minipage}{\linewidth}
\begin{lstlisting}
/// A minimal probabilistic program before translation ...
#[prob]
fn f(b : bool) -> u64 {
    1729
}

/// ... and after translation by `prob`, with some details omitted
fn f(b : bool) -> (impl Fn(Trace) -> (Trace, f64, u64)) {
    move |old_trace : Trace| {
        let mut new_trace = Trace::Function("f", Vec::new());
        /* ... */
        (new_trace, total_probability, 1729)
    }
}
\end{lstlisting}
\end{minipage}

Furthermore, \lstinline{prob} injects the necessary code into any loops (\lstinline{loop}, \lstinline{while} and \lstinline{for} expressions) inside the program such that a subtrace is created for every iteration. For the scope of the loop's body, the trace of the outer scope is shadowed over by this subtrace.

\begin{minipage}{\linewidth}
\begin{lstlisting}
// A for loop before translation ...
let mut c = 1;
for i in 0..10 {
    c *= i;
}

// ... and after translation by `prob`
let mut c = 1;
{
    let mut loop_counter = 0;
    for i in 0..10 {
        let old_trace = old_trace.pop();
        let new_trace = new_trace.push(
            Trace::Loop(loop_counter, Vec::new()));

        c *= i;

        loop_counter += 1;
    }
}
\end{lstlisting}
\end{minipage}

\subsection{sample \& observe}

Rather than being part of \lstinline{prob}, the special treatment of sample and observe statements is implemented by defining for each a function-like macro that expects \lstinline{old_trace}, \lstinline{new_trace} and \lstinline{total_probability} to already exist in the current context and adds to them accordingly.

\begin{minipage}{\linewidth}
\begin{lstlisting}
// A sample expression ...
sample!(uniform(0.,1.))

// ... turns into a normal expression
{
    let (value, probability) =
        resample(uniform(0.,1.), old_trace, &mut new_trace);
    total_probability *= probability;
    value
}
\end{lstlisting}
\end{minipage}

\begin{minipage}{\linewidth}
\begin{lstlisting}
// An observe statement ...
observe!(bernoulli(0.5), true);

// ... turns into a normal statement
total_probability *= probability(bernoulli(0.5), true);
\end{lstlisting}
\end{minipage}

The implementation of the Metropolis Hastings algorithm can with this be simply defined to operate on any ordinary function that has the signature

\begin{equation*}
    Fn(\&mut Trace) \rightarrow (T, f64)
\end{equation*}

for some type $T$. Otherwise, it is a direct implementation of the procedure described in the previous section.
