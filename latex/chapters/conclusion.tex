\section{Conclusion}

The implementation of probabilistic programming presented in this paper allows for writing arbitrarily complex probabilistic programs. However, in practice, the convergence and overall performance of the basic Metropolis Hastings inference algorithm we've covered here can be rather subpar and would have been up to the state of the art over a decade ago \cite{wingate2011lightweight}. Both on the front of inference algorithms and the implementation details of tracing and embedding there has been made great progress in this time \cite{wood2014new} \cite{cusumano2019gen}. There has been in particular a focus on integrating probabilistic programs with currently prevalent neural network methods and corresponding frameworks, such that a combination of both principles of can be employed in practice \cite{bingham2019pyro} \cite{cusumano2019gen}. However, the core idea of exploring the space of traces of a probabilistic program to draw samples from the distribution it represents has remained the same. And while many different inference algorithms and variants thereof have been proposed, it remains an active research objective to develop truly universally applicable inference algorithms \cite{lew2023smcp3}.

In terms of application, probabilistic programming has, either on its own or in conjunction with neural network methods, successfully been used for artificial intelligence engineering efforts like 3D shape inference \cite{mansinghka2013approximate} \cite{hoffman2023probnerf}, and as a way to model human cognition \cite{griffiths2010probabilistic} \cite{stuhlmuller2015modeling}.
