\section{Introduction}

For various systems across many fields of interest, randomness can be useful in developing tractable models by abstracting over the dynamics of some complex process, such as for example the physics of a coin flying through the air being abstracted over with a simple Bernoulli distribution to model it's behavior of either landing on heads or tails. Unlike different methods of abstraction, like approximate simulation, if constructed accurately, a distribution can precisely capture a part of the behavior of a system without having to fully reproduce it's internal mechanics. Specifically, while a single draw from a distribution will not necessarily match some observed behavior, the characteristics of a total of draws will approach the characteristics of an equal number of independent observations.

While there are many examples of the behavior of principally rather complex systems being well approximated by mathematically simple distributions, like for example the distribution of beans in a "bean machine" following a normal distribution, most systems of practical interest do not give rise to such easily describable distributions. Rather, to develop a stochastic abstraction over the mechanics of many systems requires the arbitrarily complex composition of simple distributions, to a point that it can become difficult or even impossible to analytically answer questions of interest about the resulting total distribution.

However, many characteristics about a complex distribution can still be approximated by "Monte Carlo methods", which rather than analytically working on the structure of a distribution itself to obtain results instead compute numerical approximations by taking random samples from the distribution, just as one would statistically analyze observations from any process. But while it no longer is required for our target distribution to be fully analytically comprehensible to apply a Monte Carlo method of approximation, it is crucially still necessary to have the means to obtain a large number of samples from our distribution, which itself can already be rather difficult to develop for many complex distributions. It is often times much easier to at least compute the probability of some given value having been drawn from a certain distribution. "Markov Chain Monte Carlo methods" (MCMC) allow us to indirectly draw samples in such a case. There principle operation thereby is to iteratively explore the space of values that might be drawn from a distribution by taking repeated randomized steps through it and for each step deciding whether to take it or to revert back to the previous value. If the method of proposing steps to take and deciding whether to accept or reject them is chosen correctly, the resulting sequence of values will converge to a distribution which matches the target distribution.

While MCMC methods are widely used in various fields of application, such as physics, economics and many other endeavors of both academia and industry, and routinely applied to potentially very high-dimensional and complex stochastic models, these are still commonly drawn from a computationally significantly constrained class such as generalized linear models. We will here consider a much wider class of models, that of probabilistic programs.

For our purposes, a probabilistic program is a function in a Turing-complete imperative programming language which can contain two additional elements besides the language's regular semantics: Instances of sampling from predefined primitive distributions or other probabilistic programs, and statements of observing some value from some primitive distribution.

Introducing randomness into an otherwise deterministic program is itself not much of a significant change to the execution model of a programming language with persistent state, with most everyday programming languages having some readily provided means of getting random, or at the least pseudo-random, samples for various practically relevant distributions. So without any change to execution, we can model many computationally complex distributions by simply writing some function which utilizes such primitive distributions. Drawing samples from the composite distribution then directly corresponds to executing this function.

However, in many practical tasks, we might not simply want to obtain some value from a distribution and run with it, but rather wish to express a constraint on such a value. For a very common practical example, we might have some complex generative stochastic model, written as a probabilistic program, and some empirical observations of data from some real-life system we wish to understand, and want to know which instances of of our model reproduce most closely this data.

One straightforward possibility would be to simply run our program many times and reject samples which do not fit the observed data. This method of "rejection sampling" is feasible for relatively simple models with a small space of possible output values, if however perhaps computationally somewhat wasteful. But for any more complex model, and especially for distributions over a non-finite domain, this method is infeasible. Rather, an approach which more efficiently explores the possible executions of a probabilistic program is necessary.

To solve this problem with MCMC methods, three considerations have to be made: What is the space over which we define our distribution which we will explore? How will we be able to compute the probability of some sample coming from our distribution? How will we efficiently step through this space while also fulfilling the constraints necessary for our algorithm to efficiently sample from the target distribution?

While there are many answers to the final of these three questions, the first two have relatively straightforward solutions. The space we will explore with MCMC is the space of possible executions of a probabilistic program at hand. And to calculate the probability of getting some particular execution of the program, we evaluate the program and accumulate the probabilities of the individual draws and observations of values from primitive distributions as we encounter them during execution.
