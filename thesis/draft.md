# Motivation

For various systems across many fields of interest, randomness can be useful in developing tractable models by abstracting over the dynamics of some complex process, such as for example the physics of a coin flying through the air being abstracted over with a simple Bernoulli distribution to model it's behaviour of either landing on heads or tails. Unlike different methods of abstraction, like approximate simulation, if constructed acccurately, a distribution can precisely capture a part of the behaviour of a system, without having to fully reproduce it's internal mechanics. Specifically, while a single draw from a distribution will not necessarily match some observed behaviour, the total characteristics of a large number of draws will match the characteristics of an equal number of independent observations.

While there are many examples of the behaviour of principally rather complex systems being very well approximated by mathematically simple distributions, like for example the distribution of beans in a "bean machine" following roughly a normal distribution, most systems of practical interest do not give rise to such easily describable distributions. Rather, to develop a stochastic abstraction over such a system's mechanics requires arbitrarily complex composition of simple distributions, to a point that it can become difficult or even impossible to analytically answer questions of interest about the distribution at hand. For example, while it might be easy to directly calculate the expected value of some distributions or even simple combinations of distributions, like a sum of simple real-valued distributions, for many complex distributions this no longer is possible.

However, many characteristics about a complex distribution can still obtained by a general category of methods termed "Monte Carlo methods", which rather than analytically working on the structure of a distribution itself to obtain results, instead compute numerical approximations by taking random samples from the distribution, just as one would statistically analyze observations from a non-stochastic system.

While it no longer is required for our target distribution to be analytically tractable to apply any Monte Carlo method of approximation, it is still necessary to have the means to obtain a large number of samples from our distribution, which itself can already be rather difficult to develop for many complex distributions. But while it might be difficult to generate samples, often times it is much easier to compute the probability of some given value having been drawn from a certain distribution.

To still obtain samples from such a distribution where the only practically computable function is getting the probability of some value being drawn from the distribution, a class of algorithms termed "Markov Chain Monte Carlo methods" (MCMC) have been developed. The principle operation of these methods is to explore the space of values that might be drawn from a distribution by taking repeated randomized steps through it and for each step deciding whether to take it ("accept") or to revert back to the previous value ("reject"). If the method of proposing steps to take and deciding whether to accept or reject them is chosen correctly, the resulting Markov chain of values will converge to a distribution which matches the complex target distribution. This way, we can generate samples from a distribution without having to actually be able to directly draw such samples, allowing us to use Monte Carlo methods to get approximations for characteristics of interest about our distribution.

# Markov Chain Monte Carlo

In contrast to any other sequence of values, a Markov chain is characterized the property that every value in the chain is determined at most by the directly preceding value and therefore is independent of the history of values preceding it's predecessor. If considered as a series of steps through some space of values, this means that every step we take is only based on where we currently are in the space, and not how we got there.

The advantage of such a forgetful sequence is that it is possible to prove general propositions about it's behaviour, such as whether or not it will converge towards a stable distribution and what this distribution will look like. 